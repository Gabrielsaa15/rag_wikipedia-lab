{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4924b447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e76131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wikipediaapi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import pandas as pd\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2570d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../data\")\n",
    "OUT_DIR = Path(\"../outputs\")\n",
    "PERSIST_DIR = DATA_DIR / \"chroma\"\n",
    "DATA_DIR.mkdir(exist_ok=True, parents=True)\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "CSV_RAW = DATA_DIR / \"wiki_corpus.csv\"\n",
    "CSV_CHUNKS = DATA_DIR / \"wiki_chunks.csv\"\n",
    "\n",
    "TOPIC = \"Federated_learning\"  # puedes cambiarlo (en/es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8820d84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] ../data/wiki_corpus.csv escrito. Título: Federated learning. Longitud texto: 31699\n",
      "Muestra: Federated learning (also known as collaborative learning) is a machine learning technique in a setting where multiple entities (often called clients) collaboratively train a model while keeping their data decentralized, rather than centrally stored. A defining characteristic of federated learning is data heterogeneity. Because client data is decentralized, data samples held by each client may not \n"
     ]
    }
   ],
   "source": [
    "wiki = wikipediaapi.Wikipedia(language='en', user_agent='rag-wikipedia-lab/1.0')\n",
    "page = wiki.page(TOPIC)\n",
    "\n",
    "if not page.exists():\n",
    "    raise ValueError(f\"La página '{TOPIC}' no existe.\")\n",
    "\n",
    "title = page.title\n",
    "text = page.text  # texto plano, ideal para NLP\n",
    "\n",
    "# Guardamos un solo registro: id, title, text\n",
    "df = pd.DataFrame([{\"id\": f\"wiki:{TOPIC}\", \"title\": title, \"text\": text}])\n",
    "df.to_csv(CSV_RAW, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"[OK] {CSV_RAW} escrito. Título: {title}. Longitud texto: {len(text)}\")\n",
    "print(\"Muestra:\", text[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a0eecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 37 chunks → ../data/wiki_chunks.csv\n",
      "Federated learning (also known as collaborative learning) is a machine learning technique in a setting where multiple entities (often called clients) collaboratively train a model while keeping their data decentralized, rather than centrally stored. A defining characteristic of federated learning is\n"
     ]
    }
   ],
   "source": [
    "raw = pd.read_csv(CSV_RAW)\n",
    "doc_id, title, raw_text = raw.loc[0, \"id\"], raw.loc[0, \"title\"], raw.loc[0, \"text\"]\n",
    "\n",
    "# Limpieza mínima: colapsa espacios/saltos\n",
    "clean = \" \".join(str(raw_text).split())\n",
    "\n",
    "# Splitter recursivo respeta separadores; solape preserva contexto entre trozos\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      # ~300–350 palabras típico\n",
    "    chunk_overlap=150,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(clean)\n",
    "\n",
    "rows = [{\n",
    "    \"chunk_id\": f\"{doc_id}::chunk_{i:04d}\",\n",
    "    \"title\": title,\n",
    "    \"text\": ch\n",
    "} for i, ch in enumerate(chunks)]\n",
    "\n",
    "pd.DataFrame(rows).to_csv(CSV_CHUNKS, index=False, encoding=\"utf-8\")\n",
    "print(f\"[OK] {len(rows)} chunks → {CSV_CHUNKS}\")\n",
    "print(rows[0][\"text\"][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdd84e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:01<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Indexado en Chroma.\n",
      "Colección: wiki_ai | num items: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "COLLECTION_NAME = \"wiki_ai\"\n",
    "EMB_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"  # rápido y bueno\n",
    "\n",
    "# Carga chunks\n",
    "dfc = pd.read_csv(CSV_CHUNKS)\n",
    "\n",
    "# Cliente Chroma persistente\n",
    "client = chromadb.Client(Settings(persist_directory=str(PERSIST_DIR)))\n",
    "\n",
    "# Crea/recupera colección\n",
    "existing = [c.name for c in client.list_collections()]\n",
    "collection = client.get_collection(COLLECTION_NAME) if COLLECTION_NAME in existing \\\n",
    "    else client.create_collection(COLLECTION_NAME, metadata={\"topic\": TOPIC})\n",
    "\n",
    "# Embeddings con SentenceTransformer\n",
    "emb_model = SentenceTransformer(EMB_MODEL_NAME)\n",
    "\n",
    "ids = dfc[\"chunk_id\"].tolist()\n",
    "texts = dfc[\"text\"].tolist()\n",
    "metas = [{\"title\": t} for t in dfc[\"title\"].tolist()]\n",
    "\n",
    "vectors = emb_model.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n",
    "assert vectors.shape[0] == len(texts)\n",
    "\n",
    "collection.upsert(\n",
    "    ids=ids,\n",
    "    documents=texts,\n",
    "    metadatas=metas,\n",
    "    embeddings=vectors\n",
    ")\n",
    "\n",
    "print(\"[OK] Indexado en Chroma.\")\n",
    "print(\"Colección:\", COLLECTION_NAME, \"| num items:\", collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cbc68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo de contexto recuperado:\n",
      " . Moreover, the clients involved in federated learning may be unreliable as they are subject to more failures or drop out since they commonly rely on less powerful communication media (i.e. Wi-Fi) and battery-powered systems (i.e. smartphones and IoT devices) compared to distributed learning where nodes are typically datacenters that have powerful computational capabilities and are connected to on\n"
     ]
    }
   ],
   "source": [
    "# Configuración\n",
    "PERSIST_DIR = \"data/chroma\"\n",
    "model_embed = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Cargar base vectorial persistente\n",
    "client = chromadb.Client(Settings(persist_directory=PERSIST_DIR))\n",
    "collection = client.get_collection(COLLECTION_NAME)\n",
    "\n",
    "# Formulamos la pregunta\n",
    "query = \"Explain federated learning challenges in healthcare.\"\n",
    "\n",
    "# Embedding de la pregunta\n",
    "query_vec = model_embed.encode([query])\n",
    "\n",
    "# Recuperamos los 5 chunks más relevantes\n",
    "res = collection.query(\n",
    "    query_embeddings=query_vec,\n",
    "    n_results=5,\n",
    "    include=[\"documents\", \"metadatas\"]\n",
    ")\n",
    "\n",
    "# Combinamos los fragmentos en un solo contexto\n",
    "context = \"\\n\\n\".join(res[\"documents\"][0])\n",
    "print(\"Ejemplo de contexto recuperado:\\n\", context[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c40693db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Guardado retrieval_examples.json\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "queries = [\n",
    "    \"What is federated learning and how does it work?\",\n",
    "    \"Key privacy challenges in federated learning\",\n",
    "    \"Comparison between centralized and federated training\",\n",
    "    \"Explain federated learning challenges in healthcare.\"\n",
    "]\n",
    "\n",
    "examples = []\n",
    "for q in queries:\n",
    "    q_vec = model_embed.encode([q])\n",
    "    res = collection.query(query_embeddings=q_vec, n_results=5, include=[\"documents\",\"metadatas\"])\n",
    "    examples.append({\n",
    "        \"query\": q,\n",
    "        \"top_snippets\": res[\"documents\"][0],\n",
    "        \"metadata\": res[\"metadatas\"][0]\n",
    "    })\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "with open(\"../outputs/retrieval_examples.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(examples, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"[OK] Guardado retrieval_examples.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f04a7298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Guardado en outputs/rag_summary.md\n",
      "\n",
      "    You are a technical writer. Summarize the following information about Federated learning\n",
      "    in 400-500 words. Be factual, coherent, and clear.\n",
      "\n",
      "    CONTEXT:\n",
      "    . Moreover, the clients involved in federated learning may be unreliable as they are subject to more failures or drop out since they commonly rely on less powerful communication media (i.e. Wi-Fi) and battery-powered systems (i.e. sm\n"
     ]
    }
   ],
   "source": [
    "# Modelo de lenguaje local\n",
    "MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=torch.float32)\n",
    "\n",
    "def summarize_with_context(context, topic=\"Federated learning\"):\n",
    "    prompt = f\"\"\"\n",
    "    You are a technical writer. Summarize the following information about {topic}\n",
    "    in 400-500 words. Be factual, coherent, and clear.\n",
    "\n",
    "    CONTEXT:\n",
    "    {context}\n",
    "\n",
    "    SUMMARY:\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=500, do_sample=False)\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Generar resumen\n",
    "summary = summarize_with_context(context)\n",
    "\n",
    "# Guardar en archivo Markdown\n",
    "with open(\"../outputs/rag_summary.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"# Summary: Federated Learning\\n\\n{summary.strip()}\\n\")\n",
    "\n",
    "print(\"[OK] Guardado en outputs/rag_summary.md\")\n",
    "print(summary[:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ab741c",
   "metadata": {},
   "source": [
    "### Reflexión: Multi-Agente vs. RAG\n",
    "\n",
    "El enfoque **multi-agente** maneja la ambigüedad haciendo que distintos agentes colaboren y se corrijan entre sí, lo que ayuda a resolver contradicciones, aunque puede generar respuestas menos precisas.  \n",
    "El enfoque **RAG** maneja mejor la **factualidad**, porque solo usa información real recuperada de la base de datos, aunque depende de qué tan buena sea la búsqueda y la cobertura del texto.  \n",
    "En general, el método multi-agente es mejor para **preguntas abiertas o interpretativas**, mientras que **RAG** es más fácil y confiable para **preguntas factuales y concretas** y mucho más facil."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
